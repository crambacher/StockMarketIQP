{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "269f32bd-02d9-4e10-badc-cd269afed02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_94 (Dense)            (None, 1000)              6000      \n",
      "                                                                 \n",
      " batch_normalization_72 (Bat  (None, 1000)             4000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 500)               500500    \n",
      "                                                                 \n",
      " batch_normalization_73 (Bat  (None, 500)              2000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 100)               50100     \n",
      "                                                                 \n",
      " batch_normalization_74 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " batch_normalization_75 (Bat  (None, 50)               200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 5)                 255       \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 5)                 0         \n",
      "                                                                 \n",
      " batch_normalization_76 (Bat  (None, 5)                20        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 568,532\n",
      "Trainable params: 565,222\n",
      "Non-trainable params: 3,310\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "1/1 [==============================] - 4s 4s/step - loss: 88745.3750 - mean_squared_error: 88745.3750 - val_loss: 69.4629 - val_mean_squared_error: 69.4629\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 88643.9766 - mean_squared_error: 88643.9766 - val_loss: 69.4215 - val_mean_squared_error: 69.4215\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 88594.2266 - mean_squared_error: 88594.2266 - val_loss: 69.3866 - val_mean_squared_error: 69.3866\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 88471.8672 - mean_squared_error: 88471.8672 - val_loss: 69.3523 - val_mean_squared_error: 69.3523\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 88501.0625 - mean_squared_error: 88501.0625 - val_loss: 69.3252 - val_mean_squared_error: 69.3252\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 88490.6719 - mean_squared_error: 88490.6719 - val_loss: 69.3002 - val_mean_squared_error: 69.3002\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 88449.3828 - mean_squared_error: 88449.3828 - val_loss: 69.2769 - val_mean_squared_error: 69.2769\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 88435.2109 - mean_squared_error: 88435.2109 - val_loss: 69.2549 - val_mean_squared_error: 69.2549\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 88429.4922 - mean_squared_error: 88429.4922 - val_loss: 69.2346 - val_mean_squared_error: 69.2346\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 88424.6328 - mean_squared_error: 88424.6328 - val_loss: 69.2155 - val_mean_squared_error: 69.2155\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 88420.4219 - mean_squared_error: 88420.4219 - val_loss: 69.1973 - val_mean_squared_error: 69.1973\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 88417.1484 - mean_squared_error: 88417.1484 - val_loss: 69.1804 - val_mean_squared_error: 69.1804\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 88412.3750 - mean_squared_error: 88412.3750 - val_loss: 69.1644 - val_mean_squared_error: 69.1644\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 88408.3594 - mean_squared_error: 88408.3594 - val_loss: 69.1490 - val_mean_squared_error: 69.1490\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 88404.7578 - mean_squared_error: 88404.7578 - val_loss: 69.1342 - val_mean_squared_error: 69.1342\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 88400.9297 - mean_squared_error: 88400.9297 - val_loss: 69.1199 - val_mean_squared_error: 69.1199\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 88397.6172 - mean_squared_error: 88397.6172 - val_loss: 69.1062 - val_mean_squared_error: 69.1062\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 88394.5547 - mean_squared_error: 88394.5547 - val_loss: 69.0929 - val_mean_squared_error: 69.0929\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 88390.1484 - mean_squared_error: 88390.1484 - val_loss: 69.0800 - val_mean_squared_error: 69.0800\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 88386.5938 - mean_squared_error: 88386.5938 - val_loss: 69.0676 - val_mean_squared_error: 69.0676\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 88382.7344 - mean_squared_error: 88382.7344 - val_loss: 69.0557 - val_mean_squared_error: 69.0557\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 88378.9531 - mean_squared_error: 88378.9531 - val_loss: 69.0446 - val_mean_squared_error: 69.0446\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 88376.3984 - mean_squared_error: 88376.3984 - val_loss: 69.0331 - val_mean_squared_error: 69.0331\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 88373.8906 - mean_squared_error: 88373.8906 - val_loss: 69.0224 - val_mean_squared_error: 69.0224\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 88369.2422 - mean_squared_error: 88369.2422 - val_loss: 69.0120 - val_mean_squared_error: 69.0120\n",
      "Test loss: 832192.4375 / Test MSE: 832192.4375\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (Temp/ipykernel_22436/3069888403.py, line 66)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Calvin\\AppData\\Local\\Temp/ipykernel_22436/3069888403.py\"\u001b[1;36m, line \u001b[1;32m66\u001b[0m\n\u001b[1;33m    return model\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from numpy import loadtxt\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "batch_size = 250000\n",
    "no_epochs = 25\n",
    "no_classes = 100\n",
    "validation_split = 0.1\n",
    "verbosity = 1\n",
    "\n",
    "accepted_diff = 0.01\n",
    "def linear_regression_equality(y_true, y_pred):\n",
    "    diff = K.abs(y_true-y_pred)\n",
    "    return K.mean(K.cast(diff < accepted_diff, tf.float32))\n",
    "\n",
    "#stock_train_x = loadtxt(\"TSLA_Year_Training_X.csv\", delimiter=',')\n",
    "\n",
    "#stock_train_y = pd.read_csv(\"TSLA_Year_Training_Y.csv\")\n",
    "#stock_train_y = tf.convert_to_tensor(stock_train_y, dtype=tf.float32)\n",
    "\n",
    "#x = stock_train_x[:,0:6]\n",
    "#y = stock_train_y[:,0]\n",
    "\n",
    "stock_train = loadtxt(\"TSLA_Training_Full.csv\", delimiter=',')\n",
    "x = stock_train[:,0:5]\n",
    "y = stock_train[:,5]\n",
    "\n",
    "stock_test = loadtxt(\"TSLA_Testing_Full.csv\", delimiter=',')\n",
    "x_test = stock_test[:,0:5]\n",
    "y_test = stock_test[:,5]\n",
    "\n",
    "layer = tf.keras.layers.Normalization(axis=-1)\n",
    "layer.adapt(stock_train)\n",
    "layer(stock_train)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=5, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(500, activation = 'sigmoid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(100, activation = 'sigmoid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(50, activation = 'sigmoid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(5, activation = 'sigmoid'))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation = 'PReLU'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['mean_squared_error']) \n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x, y, epochs=no_epochs, batch_size = batch_size, verbose=verbosity, validation_split=validation_split)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test MSE: {score[1]}')\n",
    "\n",
    "return model\n",
    "#actual test\n",
    "\n",
    "prediction=model.predict_classes(content_of_new_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5e38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c81a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
